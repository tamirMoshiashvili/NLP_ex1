1. We took the last 10% lines from the corpus to use for the unknown words.
   Unknown word will be marked in the code as the variable UNK and equals to '_UNK_'.
   When we reach the last 10% of the lines in the corpus, and the given word was not seen before,
    the word is set to UNK and enter the needed data with UNK (the data for e.mle and q.mle) .

2. In Viterbi-HMM, the pruning strategy was to use for each word only the tags that seen before for that specific word.
   If the word is unknown, so the tag-set will be only the tags that was seen for UNK.
   So in the algorithm, we won't try to evaluate every tag in the tag-set, but only the tags that was seen before.

3. NOTE - The following results are only for the POS data,
          the results for NER data are in the 'ner'-directory.
   GreedyTag:       93.04%
   HMMTag:          94.88%
   GreedyMaxEntTag: 95.6%
   MEMMTag:         96.4%

4. The HMM-taggers are significantly faster than the MEMM-taggers,
   but the MEMM-taggers provide better accuracies on the data-sets than the HMM-taggers.

5. Tagging the NER data had better precision than tagging the POS data (one percent difference) .

6. Improvements in HMM Taggers:
   We found that most of the mistakes were that the tagger predicted O-tag instead of I-tag,
   so we will try to normalize the amount of O-tag in purpose,
   second approach is trying at first the I-tag as an option and only after failure try the O-tag.

7. Improvements in MEMM Taggers:
   As mentioned, the features that we used for the tagging were more related to the POS data,
   so one thing that we can change is the features, to be more related to the NER data.
   For example, capital letters are strongly related to the NER data,
    and the distance from te last I-tag, since most of the I-tags are separated (from looking at the corpus).

8. Discussion about the F-scores are in the 'ner.txt' file (3.b) .
